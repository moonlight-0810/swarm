#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SwarmChemistry Prompt Embedding Generator (æ”¯æŒç¦»çº¿/é•œåƒæº)
ä¸ºSwarmChemistryé¡¹ç›®çš„promptç”Ÿæˆè¯­ä¹‰embeddingå‘é‡

ä¾èµ–å®‰è£…ï¼š
pip install sentence-transformers numpy scikit-learn
"""

import json
import numpy as np
import os
import time
from pathlib import Path

# è®¾ç½®ç¯å¢ƒå˜é‡ä½¿ç”¨å›½å†…é•œåƒæº
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

try:
    from sentence_transformers import SentenceTransformer
    from sklearn.decomposition import PCA
    HAS_TRANSFORMERS = True
except ImportError:
    HAS_TRANSFORMERS = False
    print("âš ï¸ sentence-transformers not installed. Installing...")

class PromptEmbeddingGenerator:
    def __init__(self, model_name='all-MiniLM-L6-v2', reduce_dim=None, use_mirror=True):
        """
        åˆå§‹åŒ–embeddingç”Ÿæˆå™¨
        
        Args:
            model_name (str): sentence-transformersæ¨¡å‹åç§°
            reduce_dim (int, optional): å¦‚æœæŒ‡å®šï¼Œä½¿ç”¨PCAé™ç»´åˆ°æŒ‡å®šç»´åº¦
            use_mirror (bool): æ˜¯å¦ä½¿ç”¨å›½å†…é•œåƒæº
        """
        if use_mirror:
            # è®¾ç½®é•œåƒæº
            os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
            print(f"ğŸŒ ä½¿ç”¨å›½å†…é•œåƒæº: {os.environ.get('HF_ENDPOINT')}")
        
        print(f"ğŸš€ Loading model: {model_name}")
        
        try:
            # å°è¯•åŠ è½½æ¨¡å‹
            self.model = SentenceTransformer(model_name)
            self.reduce_dim = reduce_dim
            self.pca = None
            
            print(f"âœ… Model loaded successfully")
            print(f"ğŸ“Š Original embedding dimension: {self.model.get_sentence_embedding_dimension()}")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            print("ğŸ”„ å°è¯•ä½¿ç”¨æœ¬åœ°æ›¿ä»£æ–¹æ¡ˆ...")
            self._fallback_to_simple_embedding()
    
    def _fallback_to_simple_embedding(self):
        """å¦‚æœæ— æ³•åŠ è½½transformersæ¨¡å‹ï¼Œä½¿ç”¨ç®€å•çš„æ–‡æœ¬ç‰¹å¾ä½œä¸ºæ›¿ä»£"""
        print("âš ï¸  ä½¿ç”¨ç®€åŒ–çš„æ–‡æœ¬ç‰¹å¾æ›¿ä»£æ–¹æ¡ˆ")
        print("   è¿™ä¸æ˜¯å®Œæ•´çš„è¯­ä¹‰embeddingï¼Œä½†å¯ä»¥ç”¨äºæµ‹è¯•")
        self.model = None
        self.reduce_dim = None
        self.pca = None
    
    def _simple_text_features(self, text):
        """ç®€å•çš„æ–‡æœ¬ç‰¹å¾æå–ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        features = []
        
        # åŸºæœ¬æ–‡æœ¬ç»Ÿè®¡ç‰¹å¾
        features.append(len(text))  # æ–‡æœ¬é•¿åº¦
        features.append(len(text.split()))  # å•è¯æ•°
        features.append(text.count(' '))  # ç©ºæ ¼æ•°
        
        # å­—ç¬¦é¢‘ç‡ç‰¹å¾ï¼ˆå–å‰10ä¸ªæœ€å¸¸è§å­—ç¬¦ï¼‰
        char_freq = {}
        for char in text.lower():
            if char.isalpha():
                char_freq[char] = char_freq.get(char, 0) + 1
        
        # é€‰æ‹©å›ºå®šçš„ç‰¹å¾ç»´åº¦
        common_chars = 'abcdefghijklmnopqrstuvwxyz'
        for char in common_chars:
            features.append(char_freq.get(char, 0))
        
        # ä¸€äº›ç®€å•çš„è¯­ä¹‰ç‰¹å¾
        emotional_words = ['joy', 'happy', 'sad', 'angry', 'fear', 'love', 'hate']
        for word in emotional_words:
            features.append(1 if word in text.lower() else 0)
        
        nature_words = ['flower', 'tree', 'water', 'fire', 'earth', 'sky', 'ocean']
        for word in nature_words:
            features.append(1 if word in text.lower() else 0)
        
        # å¡«å……åˆ°å›ºå®šç»´åº¦ï¼ˆ50ç»´ï¼‰
        while len(features) < 50:
            features.append(0.0)
        
        return np.array(features[:50], dtype=np.float32)
    
    def generate_embeddings(self, prompts):
        """
        ä¸ºpromptåˆ—è¡¨ç”Ÿæˆembeddingå‘é‡
        
        Args:
            prompts (list): promptå­—ç¬¦ä¸²åˆ—è¡¨
            
        Returns:
            numpy.ndarray: embeddingçŸ©é˜µ
        """
        print(f"ğŸ”„ Generating embeddings for {len(prompts)} prompts...")
        
        if self.model is not None:
            # ä½¿ç”¨çœŸå®çš„transformersæ¨¡å‹
            embeddings = self.model.encode(prompts, show_progress_bar=True)
            
            # å¯é€‰ï¼šé™ç»´å¤„ç†
            if self.reduce_dim and self.reduce_dim < embeddings.shape[1]:
                print(f"ğŸ”§ Reducing dimensions from {embeddings.shape[1]} to {self.reduce_dim}")
                self.pca = PCA(n_components=self.reduce_dim)
                embeddings = self.pca.fit_transform(embeddings)
                print(f"âœ… Dimension reduction completed")
        else:
            # ä½¿ç”¨ç®€å•çš„æ–‡æœ¬ç‰¹å¾
            print("âš ï¸  ä½¿ç”¨ç®€åŒ–ç‰¹å¾ç”Ÿæˆembedding...")
            embeddings = np.array([self._simple_text_features(prompt) for prompt in prompts])
            
        return embeddings
    
    def process_json_file(self, input_file, output_file=None):
        """
        å¤„ç†JSONæ–‡ä»¶ï¼Œæ·»åŠ embeddingå­—æ®µ
        
        Args:
            input_file (str): è¾“å…¥JSONæ–‡ä»¶è·¯å¾„
            output_file (str, optional): è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤è¦†ç›–åŸæ–‡ä»¶ï¼‰
        """
        if not os.path.exists(input_file):
            raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
            
        # è¯»å–åŸå§‹æ•°æ®
        print(f"ğŸ“– Reading data from: {input_file}")
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        if not isinstance(data, list):
            raise ValueError("JSONæ–‡ä»¶åº”è¯¥åŒ…å«ä¸€ä¸ªæ•°ç»„")
            
        # æå–æ‰€æœ‰prompt
        prompts = []
        for item in data:
            if 'prompt' not in item:
                raise ValueError(f"æ•°æ®é¡¹ç¼ºå°‘'prompt'å­—æ®µ: {item}")
            prompts.append(item['prompt'])
            
        print(f"ğŸ“ Found {len(prompts)} prompts:")
        for i, prompt in enumerate(prompts, 1):
            print(f"  {i}. \"{prompt}\"")
            
        # ç”Ÿæˆembeddings
        embeddings = self.generate_embeddings(prompts)
        
        # æ›´æ–°æ•°æ®ç»“æ„
        print("ğŸ”„ Updating data structure...")
        for i, item in enumerate(data):
            # å°†numpyæ•°ç»„è½¬æ¢ä¸ºPythonåˆ—è¡¨ï¼Œä¿ç•™åˆç†çš„ç²¾åº¦
            embedding_list = embeddings[i].astype(np.float32).tolist()
            # å››èˆäº”å…¥åˆ°6ä½å°æ•°ä»¥å‡å°‘æ–‡ä»¶å¤§å°
            embedding_list = [round(x, 6) for x in embedding_list]
            item['embedding'] = embedding_list
            
        # ä¿å­˜ç»“æœ
        output_path = output_file or input_file
        print(f"ğŸ’¾ Saving updated data to: {output_path}")
        
        # ä½¿ç”¨ç´§å‡‘æ ¼å¼ä¿å­˜ï¼Œembeddingæ•°ç»„åœ¨ä¸€è¡Œå†…
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2, separators=(',', ': '))
            
        print(f"âœ… Processing completed successfully!")
        print(f"ğŸ“Š Statistics:")
        print(f"  - Total prompts: {len(prompts)}")
        print(f"  - Embedding dimension: {len(data[0]['embedding'])}")
        print(f"  - Output file size: {os.path.getsize(output_path) / 1024:.1f} KB")
        
        if self.model is None:
            print("âš ï¸  æ³¨æ„ï¼šä½¿ç”¨äº†ç®€åŒ–çš„ç‰¹å¾æå–æ–¹æ¡ˆ")
            print("   å»ºè®®è§£å†³ç½‘ç»œé—®é¢˜åä½¿ç”¨å®Œæ•´çš„è¯­ä¹‰embedding")
        
        return data
    
    def save_pca_model(self, filepath):
        """ä¿å­˜PCAæ¨¡å‹ç”¨äºå‰ç«¯ä¸€è‡´æ€§"""
        if self.pca is not None:
            import pickle
            with open(filepath, 'wb') as f:
                pickle.dump(self.pca, f)
            print(f"ğŸ“¦ PCA model saved to: {filepath}")

def download_model_manually():
    """æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹çš„è¯´æ˜"""
    print("ğŸ”§ æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æ–¹æ¡ˆï¼š")
    print("1. è®¿é—®: https://hf-mirror.com/sentence-transformers/all-MiniLM-L6-v2")
    print("2. ä¸‹è½½æ‰€æœ‰æ–‡ä»¶åˆ°æœ¬åœ°æ–‡ä»¶å¤¹")
    print("3. ä¿®æ”¹ MODEL_NAME ä¸ºæœ¬åœ°è·¯å¾„")
    print()

def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®å‚æ•°
    INPUT_FILE = 'public/all_prompts_results.json'  # è¾“å…¥æ–‡ä»¶è·¯å¾„
    OUTPUT_FILE = 'public/all_prompts_results_with_embeddings.json'  # è¾“å‡ºæ–‡ä»¶è·¯å¾„
    
    # æ¨¡å‹é…ç½®é€‰é¡¹
    MODELS = {
        'mirror': {
            'name': 'all-MiniLM-L6-v2',
            'use_mirror': True,
            'description': 'ä½¿ç”¨å›½å†…é•œåƒæº'
        },
        'local': {
            'name': './models/all-MiniLM-L6-v2',  # æœ¬åœ°æ¨¡å‹è·¯å¾„
            'use_mirror': False,
            'description': 'ä½¿ç”¨æœ¬åœ°æ¨¡å‹'
        },
        'simple': {
            'name': None,
            'use_mirror': False,
            'description': 'ä½¿ç”¨ç®€åŒ–ç‰¹å¾ï¼ˆä¸éœ€è¦ç½‘ç»œï¼‰'
        }
    }
    
    # é€‰æ‹©æ¨¡å‹ç­–ç•¥
    model_strategy = 'mirror'  # å¯é€‰: 'mirror', 'local', 'simple'
    
    REDUCE_DIM = None  # è®¾ç½®ä¸ºæ•´æ•°å¯ç”¨é™ç»´ï¼Œå¦‚ï¼š50, 100, æˆ– None ç¦ç”¨
    
    try:
        print("ğŸŒŠ SwarmChemistry Prompt Embedding Generator")
        print("=" * 50)
        
        selected_model = MODELS[model_strategy]
        print(f"ğŸ“‹ ä½¿ç”¨ç­–ç•¥: {selected_model['description']}")
        
        # åˆ›å»ºç”Ÿæˆå™¨
        if selected_model['name'] is None:
            # ç®€åŒ–æ¨¡å¼
            generator = PromptEmbeddingGenerator(
                model_name='dummy',
                reduce_dim=REDUCE_DIM,
                use_mirror=False
            )
            generator.model = None  # å¼ºåˆ¶ä½¿ç”¨ç®€åŒ–æ¨¡å¼
        else:
            generator = PromptEmbeddingGenerator(
                model_name=selected_model['name'],
                reduce_dim=REDUCE_DIM,
                use_mirror=selected_model['use_mirror']
            )
        
        # å¤„ç†æ–‡ä»¶
        start_time = time.time()
        result_data = generator.process_json_file(INPUT_FILE, OUTPUT_FILE)
        end_time = time.time()
        
        # å¯é€‰ï¼šä¿å­˜PCAæ¨¡å‹
        if generator.pca is not None:
            generator.save_pca_model('pca_model.pkl')
        
        print("=" * 50)
        print(f"ğŸ‰ All done! Processing time: {end_time - start_time:.2f} seconds")
        print(f"ğŸ”— Updated file ready for web integration: {OUTPUT_FILE}")
        
        # æ˜¾ç¤ºç¬¬ä¸€ä¸ªç¤ºä¾‹
        if result_data:
            sample = result_data[0]
            print(f"\nğŸ“‹ Sample result:")
            print(f"  Prompt: \"{sample['prompt']}\"")
            print(f"  Embedding shape: {len(sample['embedding'])} dimensions")
            print(f"  Parameters: {len(sample['params'])} groups")
            
    except Exception as e:
        print(f"âŒ Error: {str(e)}")
        print("\nğŸ”§ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("2. ä½¿ç”¨ç§‘å­¦ä¸Šç½‘å·¥å…·")
        print("3. æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶")
        print("4. ä½¿ç”¨ç®€åŒ–æ¨¡å¼ï¼ˆä¿®æ”¹ model_strategy = 'simple'ï¼‰")
        
        download_model_manually()
        
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 